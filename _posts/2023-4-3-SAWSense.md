---
layout: post
title: "SAWSense Receives Best Paper at CHI"
featured-img: sawsense.png
mathjax: true
category: Papers
---


[![PrivacyMic Video](http://img.youtube.com/vi/j409IOAKBEI/0.jpg)](https://www.youtube.com/watch?v=j409IOAKBEI "SAWSense")


Enabling computing systems to understand user interactions with everyday surfaces and objects can drive a wide range of applications. However, existing vibration-based sensors (e.g., accelerometers) lack the sensitivity to detect light touch gestures or the bandwidth to recognize activity containing high-frequency components. Conversely, microphones are highly susceptible to environmental noise, degrading performance. Each time an object impacts a surface, Surface Acoustic Waves (SAWs) are generated that propagate along the air-to-surface boundary. This work repurposes a Voice PickUp Unit (VPU) to capture SAWs on surfaces (including smooth surfaces, odd geometries, and fabrics) over long distances and in noisy environments. Our custom-designed signal acquisition, processing, and machine learning pipeline demonstrates utility in both interactive and activity recognition applications, such as classifying trackpad-style gestures on a desk and recognizing 16 cooking-related activities, all with >97% accuracy. Ultimately, SAWs offer a unique signal that can enable robust recognition of user touch and on-surface events.

[ACM DL](https://doi.org/10.1145/3544548.3580991) [![pdf](/assets/icons16/pdf-icon.png)]({{ BASE_PATH }}/assets/pdf/Iravantchi23SAWSense.pdf) [SAWSense Video](https://www.youtube.com/watch?v=j409IOAKBEI)